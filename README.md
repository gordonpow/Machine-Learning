# 1. SVM 的訓練過程推導

支持向量機（SVM）的目標是找到一個超平面將資料點進行分類，並且使得分類邊界與資料點之間的距離最大化。

## a. 定義問題

假設我們有一組標註好的資料集 $\{(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\}$，其中 $x_i \in \mathbb{R}^d$ 是資料點，$y_i \in \{-1, +1\}$ 是其標籤。

SVM 的目標是找到一個超平面，該超平面可以由以下方程表示：

$$
w \cdot x + b = 0
$$

其中，$w \in \mathbb{R}^d$ 是超平面的法向量，$b$ 是偏置項。

## b. 最大化間隔

SVM 的核心目標是最大化從支持向量（離超平面最近的資料點）到超平面的距離。假設超平面上的資料點的距離是 1，那麼兩個類別的資料點應該分開並且距離最大的邊界為 2。

我們的目標是最大化此間隔，即最大化 $\frac{2}{||w||}$。

## c. 約束條件

為了使所有資料點被正確分類，對於每個資料點 $(x_i, y_i)$ 必須滿足：

$$
y_i (w \cdot x_i + b) \geq 1
$$

這樣可以保證資料點位於邊界兩側，並且間隔最大化。

## d. 目標函數

SVM 的優化問題可以表述為：

$$
\min_{w, b} \frac{1}{2} ||w||^2
$$

同時，對所有的資料點，必須滿足約束條件：

$$
y_i (w \cdot x_i + b) \geq 1, \quad i = 1, 2, \dots, n
$$

## e. 拉格朗日乘數法

為了解這個問題，我們使用拉格朗日乘數法，將約束條件引入到目標函數中。拉格朗日函數為：

$$
L(w, b, \alpha) = \frac{1}{2} ||w||^2 - \sum_{i=1}^{n} \alpha_i \left( y_i (w \cdot x_i + b) - 1 \right)
$$

其中，$\alpha_i \geq 0$ 是拉格朗日乘數。

## f. KKT條件與最優解

經過拉格朗日對偶轉換和 KKT 條件（Karush-Kuhn-Tucker 條件），可以得到最終的優化問題，解出 $w$ 和 $b$。

---
