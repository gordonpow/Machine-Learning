# Machine-Learning
# HW1 æ¨å°èˆ‡å¯¦ä½œèªªæ˜

æœ¬ä½œæ¥­ä¸»è¦é‡å°ä»¥ä¸‹å…©å€‹æ¨¡å‹é€²è¡Œè¨“ç·´éç¨‹çš„æ•¸å­¸æ¨å°èˆ‡ç¨‹å¼å¯¦ç¾èªªæ˜ï¼š

1. SVMï¼ˆSupport Vector Machineï¼‰
2. MLPï¼ˆMultilayer Perceptronï¼‰

---

## ğŸ“˜ 1. SVM çš„è¨“ç·´éç¨‹

### ğŸ¯ ç›®æ¨™

å°æ–¼è¨“ç·´è³‡æ–™ \( (x_i, y_i) \)ï¼Œå…¶ä¸­ \( y_i \in \{+1, -1\} \)ï¼ŒSVM å¸Œæœ›æ‰¾åˆ°ä¸€å€‹åˆ†é¡è¶…å¹³é¢ï¼š

\[
f(x) = \vec{w}^T x + b
\]

ä½¿å¾—æ‰€æœ‰è³‡æ–™é»è¢«æ­£ç¢ºåˆ†é¡ä¸”**é–“éš”æœ€å¤§**ã€‚

---

### âœ… æœ€ä½³åŒ–å•é¡Œï¼ˆç¡¬é–“éš” SVMï¼‰

\[
\min_{\vec{w}, b} \frac{1}{2} ||\vec{w}||^2 \\
\text{subject to } y_i (\vec{w}^T x_i + b) \geq 1 \quad \forall i
\]

é€éæ‹‰æ ¼æœ—æ—¥ä¹˜æ•¸æ³•å¯ä»¥å°å‡ºï¼š

\[
\vec{w} = \sum_i \alpha_i y_i x_i
\]

---

### ğŸ§  æ¢¯åº¦ä¸‹é™å½¢å¼ï¼ˆSoft Margin + Hinge Lossï¼‰

å°‡å•é¡Œè½‰ç‚º soft-margin SVM çš„å½¢å¼ï¼š

\[
\min_{\vec{w}} \frac{\lambda}{2} ||\vec{w}||^2 + \frac{1}{N} \sum_{i=1}^N \max(0, 1 - y_i \vec{w}^T x_i)
\]

é€é SGD æ›´æ–°æ¬Šé‡ï¼š

\[
\vec{w}^* = \vec{w} + \Delta \vec{w}
\]

å…¶ä¸­ï¼š

\[
\Delta \vec{w} = 
\begin{cases}
-\eta \lambda \vec{w} + \eta y_i x_i & \text{if } y_i \vec{w}^T x_i < 1 \\
-\eta \lambda \vec{w} & \text{otherwise}
\end{cases}
\]

---

## ğŸ“˜ 2. MLP çš„è¨“ç·´éç¨‹

### ğŸ¯ ç›®æ¨™

é€éå¤šå±¤ç¥ç¶“ç¶²è·¯å°è¼¸å…¥ \( x \) é æ¸¬è¼¸å‡º \( \hat{y} \)ï¼Œä¸¦æœ€å°åŒ–æå¤±å‡½æ•¸ï¼ˆå¦‚ MSE æˆ–äº¤å‰ç†µï¼‰ã€‚

---

### âœ… å‰å‘å‚³æ’­ï¼ˆForward Passï¼‰

æ¯å±¤çš„è¨ˆç®—ç‚ºï¼š

\[
z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)} \\
a^{(l)} = \sigma(z^{(l)})
\]

æœ€å¾Œè¼¸å‡ºï¼š

\[
\hat{y} = a^{(L)}
\]

---

### âœ… æå¤±å‡½æ•¸ï¼ˆä»¥ MSE ç‚ºä¾‹ï¼‰

\[
L = \frac{1}{2} ||y - \hat{y}||^2
\]

---

### âœ… åå‘å‚³æ’­ï¼ˆBackpropagationï¼‰

å¾æœ€å¾Œä¸€å±¤å¾€å‰æ¨ï¼š

\[
\delta^{(L)} = \nabla_a L \odot \sigma'(z^{(L)}) \\
\delta^{(l)} = ((W^{(l+1)})^T \delta^{(l+1)}) \odot \sigma'(z^{(l)})
\]

---

### âœ… æ¬Šé‡æ›´æ–°

å°æ¯å±¤ä½¿ç”¨æ¢¯åº¦ä¸‹é™ï¼š

\[
\Delta W^{(l)} = -\eta \cdot \delta^{(l)} (a^{(l-1)})^T \\
W^{(l)} \leftarrow W^{(l)} + \Delta W^{(l)}
\]

ç¨‹å¼ä¸­è¡¨ç¤ºç‚ºï¼š

```python
W = W + delta_W  # delta_W = -learning_rate * gradient
